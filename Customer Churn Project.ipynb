{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322efe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Project:- Binary Classification on ‘Customer_Churn’using Keras #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6afc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Problem Statement:-\n",
    "##### You are the Data Scientist at a telecom company “Leo” whose customers are churning out to its competitors. You have to \n",
    "##### analyse the data of your company and find insights and stop your customers from churning out to other telecom companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c16ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Domain:– Telecom\n",
    "\n",
    "##### Domain Context:–\n",
    "##### Customer churn, in simple terms means that the customer has stopped doing business with the company and this is a common \n",
    "##### problem when it comes to telecom industries. To avoid this, companies use predictive analysis to gauge the factors \n",
    "##### responsible for a customer to leave the company. These churn prediction models help in finding out the customer base that \n",
    "##### are most likely to churn out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abbf1fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Let's import the necessary libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, KBinsDiscretizer, LabelEncoder\n",
    "##### Column Transformer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d829c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Let's import the dataset.\n",
    "\n",
    "customer = pd.read_csv('customer_churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5485d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### A. Data Manipulation:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814fbd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### a. Find the total number of male customers.\n",
    "\n",
    "sum(customer['gender']==\"Male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### b. Find the total number of customers whose Internet Service is ‘DSL’.\n",
    "\n",
    "sum(customer['InternetService']==\"DSL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4165b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### c. Extract all the Female senior citizens whose Payment Method is Mailed check & store the result in ‘new_customer’.\n",
    "\n",
    "new_customer=customer[(customer['gender']=='Female') &\n",
    "(customer['SeniorCitizen']==1) & (customer['PaymentMethod']=='Mailed check')]\n",
    "new_customer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### d. Extract all those customers whose tenure is less than 10 months or their Total charges is less than 500$ & store the \n",
    "#####    result in ‘new_customer’.\n",
    "\n",
    "new_customer=customer[(customer['tenure']<10) | (customer['TotalCharges']<500)]\n",
    "new_customer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e165b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### B. Data Visualization:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f94af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### a. Build a pie-chart to show the distribution of customers would be churning out.\n",
    "\n",
    "names = customer[\"Churn\"].value_counts().keys().tolist()\n",
    "sizes= customer[\"Churn\"].value_counts().tolist()\n",
    "\n",
    "## We are starting off by extracting the names of the levels in the churn column, then we extracting the counts of the levels in\n",
    "## the churn column.\n",
    "\n",
    "plt.pie(sizes,labels=names,autopct=\"%0.1f%%\")\n",
    "plt.show()\n",
    "\n",
    "## Using plt.pie(), we are making the pie-chart. ‘autopct’ parameter is used to add the percentage distribution in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba08bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### b. Build a bar-plot to show the distribution of ‘Internet Service’.\n",
    "\n",
    "plt.bar(customer['InternetService'].value_counts().keys().tolist(),customer['InternetServic\n",
    "e'].value_counts().tolist(),color='orange')\n",
    "                                                                            \n",
    "## We are creating the bar-plot using plt.bar()\n",
    "                                                                            \n",
    "plt.xlabel('Categories of Internet Service')\n",
    "plt.ylabel('Count of categories')\n",
    "plt.title('Distribution of Internet Service')\n",
    "plt.show() \n",
    "\n",
    "## Going ahead, we are assigning the x-label, y-label and title to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### C. Model Building:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29741859",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### a. Build a sequential model using Keras, to find out if the customerwouldchurn or not, using ‘tenure’ as the feature and \n",
    "#####    ‘Churn’ as the dependent/target column:-\n",
    "\n",
    "##### i. The visible/input layer should have 12 nodes with ‘Relu’ as activation function.\n",
    "##### ii. This model would have 1 hidden layer with 8 nodes and ‘Relu’ as activation function\n",
    "##### iii. Use ‘Adam’ as the optimization algorithm\n",
    "##### iv. Fit the model on the train set, with number of epochs to be 150\n",
    "##### v. Predict the values on the test set and build a confusion matrix\n",
    "##### vi. Plot the ‘Accuracy vs Epochs’ graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086dea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=customer[['tenure']]\n",
    "y=customer[['Churn']]\n",
    "\n",
    "## We are starting off by extracting the target and feature columns.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
    "\n",
    "## Going ahead, we are dividing the data into train and test sets using train_test_split().\n",
    "## Here, we are setting the test_size to be 0.30, which means 30% of the records go into the test set, while 70% of the records \n",
    "## go into the train set.\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=1, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "## After that we create an instance of a sequential model by using Sequential().\n",
    "## Going ahead we will add the input layer to our model. This input layer would comprise of 12 nodes and would have ‘relu’ as \n",
    "## the activation function. After that we’ll add a hidden layer with 8 nodes and ‘relu’ as activation function. Finally, we’ll\n",
    "## add the output layer which would comprise of just one node and ‘sigmoid’ as activation function.\n",
    "## We are using ‘sigmoid’ here because this is a binary classification problem and ‘sigmoid’gives us a probability between0 & 1.\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "## Further, we’ll tune the model. Here, we are using ‘binary_crossentropy’ as our loss function because this is a binary \n",
    "## classification problem.\n",
    "## Optimizer used is ‘adam’ and we would want to calculate the accuracy.\n",
    "\n",
    "model.fit(x_train, y_train, epochs=150,validation_data=(x_test,y_test))\n",
    "\n",
    "## Going ahead, we will fit the model on the train set and evaluate it on top of the test set. The number of epochs given over \n",
    "## here is 150.\n",
    "## This gives us a final validation accuracy of 75.64%. But this is not the average accuracy across 150 epochs, so let’s also \n",
    "## find that:-\n",
    "\n",
    "import numpy as np\n",
    "np.mean(model.history.history['val_acc'])\n",
    "\n",
    "## So, the mean accuracy comes out to be 75.62%.\n",
    "\n",
    "y_pred=model.predict_classes(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)\n",
    "\n",
    "## Further, we will, predict the values on ‘x_test’ and build a confusion matrix with the actual values and the predicted values.\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### b. Build the 2nd model using same target and feature variables:-\n",
    "\n",
    "##### i. Add a drop-out layer after the input layer with drop-out value of 0.3\n",
    "##### ii. Add a drop-out layer after the hidden layer with drop-out value of 0.2\n",
    "##### iii. Predict the values on the test set and build a confusion matrix\n",
    "##### iv. Plot the ‘Accuracy vs Epochs’ graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11855ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=1, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "## Now, we are building our 2nd model, where we are adding a drop-out layer after the input layer and the hidden layer.\n",
    "## Drop-out value of 0.3 means that 70% of the nodes in the input layer will be dropped out.\n",
    "## Drop-out value of 0.2 means that 80% of the nodes in the hidden layer will be dropped out.\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=150,validation_data=(x_test,y_test))\n",
    "y_pred = model.predict_classes(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.show()\n",
    "\n",
    "## After this, we have fit the model and predicted the values.\n",
    "## So, we see that the 2nd model gives us a final validation accuracy of 73.41%. Now, let’s calculate the mean validation \n",
    "## accuracy across 150 epochs:\n",
    "\n",
    "import numpy as np\n",
    "np.mean(model.history.history['val_acc'])\n",
    "\n",
    "## So, the mean accuracy comes out to be 73.42%.\n",
    "\n",
    "## By looking at this graph, we can infer that the validation accuracy is constantly 73.41%. Now, this tells us that something \n",
    "## is wrong with our model.\n",
    "\n",
    "## The most probable explanation for this is the drop-out percentage is very high for the input layer and the hidden layer and \n",
    "## thus the model which we have built might be underfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b66377",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### c. Build the 3rd model using ‘Tenure’, ’Monthly Charges’ & ‘Total Charges’ as the features and ‘Churn’ as the dependent/\n",
    "#####    target column:-\n",
    "\n",
    "##### i. The visible/input layer should have 12 nodes with ‘Relu’ as activation function.\n",
    "##### ii. This model would have 1 hidden layer with 8 nodes and ‘Relu’ as activation function\n",
    "##### iii. Use ‘Adam’ as the optimization algorithm\n",
    "##### iv. Fit the model on the train set, with number of epochs to be 150\n",
    "##### v. Predict the values on the test set and build a confusion matrix\n",
    "##### vi. Plot the ‘Accuracy vs Epochs’ graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3883217",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=customer[['MonthlyCharges','tenure','TotalCharges']]#Features\n",
    "y=customer[['Churn']]#Target\n",
    "\n",
    "## This time, we are taking ‘Monthly Charges’, ‘Total Charges’ and ‘Tenure’ as the features and ‘Churn’ as the target.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=3, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=150,validation_data=(x_test,y_test))\n",
    "y_pred = model.predict_classes(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.show()\n",
    "\n",
    "## After this, we divide the data into train and test sets and build the model on train test and predict the values on the test\n",
    "## set.\n",
    "\n",
    "## So, we see that we get a final validation accuracy of 78.58%.\n",
    "\n",
    "## But, when we look at this graph, we see that there is a constant fluctuation in the validation accuracy.\n",
    "\n",
    "## So, let’s find out the mean validation accuracy across 150 epochs:\n",
    "import numpy as np\n",
    "np.mean(model.history.history['val_acc'])\n",
    "\n",
    "## And this gives a mean validation accuracy of 74.24%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Conclusion:-\n",
    "\n",
    "##### The first model gave us a mean validation accuracy of 75.62%, the second model had accuracy of 73.42 and the third model \n",
    "##### had a mean validation accuracy of 74.24%.\n",
    "\n",
    "##### The second model gave us the least accuracy because we added two dropout layers with high probabilities of dropout.\n",
    "\n",
    "##### Now, there could be many factors why third model’s accuracy was less than that of first model. Most probably one or more \n",
    "##### of the features used during the model building could be of less significance leading to the reduction in accuracy.\n",
    "\n",
    "##### It should also be kept in mind that these accuracy values are very specific to the hyperparameters used during the model \n",
    "##### building process such as optimizers, activation functions and number of epochs. If we were to tweak these hyperparameters\n",
    "##### we would get completely different accuracy values for all the three models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
